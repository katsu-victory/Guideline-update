import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import os

# 設定
CSV_FILE = 'guidelines.csv'  # アップロードされたCSVのファイル名に合わせて変更してください
OUTPUT_FILE = 'update_report.csv'

def get_last_updated_from_web(url):
    """
    URL先のHTMLから日付情報を抽出する。
    国立がん研究センター(ganjoho.jp)の構造を主なターゲットにしています。
    """
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        # 1. 特定のクラス(例: .update)を探す
        update_text = ""
        update_element = soup.find(class_=re.compile(r'update|date|last-modified', re.I))
        if update_element:
            update_text = update_element.get_text()

        # 2. テキスト全体から日付パターン (YYYY年MM月DD日) を探す
        # サイト全体のテキストから最新の日付を抽出
        text = soup.get_text()
        date_pattern = r'(\d{4}年\d{1,2}月\d{1,2}日)'
        found_dates = re.findall(date_pattern, text)

        if found_dates:
            # 最も新しい（一番後ろに現れることが多い）日付を返す
            return found_dates[-1]
        
        return "日付未検出"
    except Exception as e:
        return f"エラー: {str(e)}"

def check_updates():
    print(f"--- 実行開始: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---")
    
    # CSVの読み込み
    try:
        df = pd.read_csv(CSV_FILE)
    except Exception as e:
        print(f"CSVの読み込みに失敗しました: {e}")
        return

    updates_found = []

    for index, row in df.iterrows():
        url = row['URL']
        current_date_in_csv = str(row['更新・確認日'])
        gl_name = row['GL名']
        
        if pd.isna(url) or not url.startswith('http'):
            continue

        print(f"確認中 ({index+1}/{len(df)}): {gl_name}...")
        
        web_date = get_last_updated_from_web(url)
        
        # 簡易的な比較（文字列の一致確認）
        # Web上の日付がCSV記載の日付と異なる場合を「更新候補」とする
        is_updated = False
        if web_date != "日付未検出" and not web_date.startswith("エラー"):
            if web_date not in current_date_in_csv:
                is_updated = True
        
        if is_updated:
            print(f"  [!] 更新の可能性あり: Web={web_date} / CSV={current_date_in_csv}")
            updates_found.append({
                'ID': row['id'],
                'GL名': gl_name,
                'URL': url,
                'CSV記載日': current_date_in_csv,
                'Web検知日': web_date,
                '確認日時': datetime.now().strftime('%Y-%m-%d')
            })

    # レポートの保存
    if updates_found:
        report_df = pd.DataFrame(updates_found)
        report_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
        print(f"\n合計 {len(updates_found)} 件の更新候補が見つかりました。詳細は {OUTPUT_FILE} を確認してください。")
    else:
        print("\n更新は見つかりませんでした。")

if __name__ == "__main__":
    check_updates()